import openai
import re
import lib.article_extractor


class Client:
    def __init__(self, config):
        self.api_key = config.api_key
        self.model = config.model or "gpt-3.5-turbo"
        self.client = openai.OpenAI(api_key=self.api_key)



    def summarize_article(self, url, max_length=280, include_hashtags=True, dry_run=False):
        """
        Summarize an article from URL and create an engaging social media post
        
        :param url: URL of the article to summarize
        :param max_length: Maximum length of the generated post
        :param include_hashtags: Whether to include relevant hashtags
        :param dry_run: If True, return mock response
        :return: Dictionary with summary and post content
        """
        if dry_run:
            return {
                "summary": "This is a dry run summary of the article",
                "social_post": f"ğŸ”¥ Amazing insights in this article! Check it out: {url} #TechNews #AI",
                "hashtags": ["#TechNews", "#AI", "#Innovation"]
            }
        
        try:
            # Extract article content
            article_data = lib.article_extractor.extract_article_content(url)
            
            # Create prompt for summarization
            hashtag_instruction = "Include 2-3 relevant Arabic hashtags." if include_hashtags else "Do not include hashtags."
            
            prompt = f"""
            Please create an engaging Arabic social media post based on this article:
            
            Title: {article_data['title']}
            Content: {article_data['content']}
            Article URL: {url}
            
            Requirements:
            - Write in Arabic
            - Keep it under {max_length} characters
            - Make it engaging and compelling
            - Include the article link at the end (just the URL, not markdown format)
            - {hashtag_instruction}
            - Use emojis strategically (3-6 relevant emojis)
            - Focus on the key insights or benefits
            - Start with an engaging hook (Ø§ÙƒØªØ´ÙØŒ ØªØ¹Ù„Ù…ØŒ Ø´Ø§Ù‡Ø¯ØŒ etc.)
            - End with a clear call to action
            
            Format the response as a ready-to-post social media message with hashtags at the end.
            """
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a social media expert who creates engaging Arabic posts that drive clicks and engagement."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            social_post = response.choices[0].message.content.strip()
            
            # Extract hashtags from the post
            hashtags = re.findall(r'#\w+', social_post)
            
            return {
                "summary": article_data['content'][:500] + "..." if len(article_data['content']) > 500 else article_data['content'],
                "social_post": social_post,
                "hashtags": hashtags,
                "title": article_data['title']
            }
            
        except Exception as e:
            raise Exception(f"Failed to summarize article: {str(e)}")

    def generate_daily_posts(self, url, num_posts=5, dry_run=False):
        """
        Generate various types of daily social media posts from an article
        Focus on informative, bite-sized, and funny content
        
        :param url: URL of the article
        :param num_posts: Number of posts to generate
        :param dry_run: If True, still generate real posts but mark as dry run
        :return: List of diverse posts (tips, facts, quotes, definitions, etc.)
        """
        # Even in dry run, we want to test the real generation for quality
        # The dry_run flag is handled at the posting level, not generation level
        
        try:
            # Extract article content
            article_data = lib.article_extractor.extract_article_content(url)
            
            # First, let's extract key information and validate content quality
            content_summary = self._analyze_article_content(article_data['content'], article_data['title'])
            
            prompt = f"""
            Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ Ø¬Ø°Ø§Ø¨ Ù„ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ. Ø§Ù‚Ø±Ø£ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø¹Ù†Ø§ÙŠØ© ÙˆØ£Ù†Ø´Ø¦ {num_posts} Ù…Ù†Ø´ÙˆØ±Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø©:

            Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø§Ù„: {article_data['title']}
            
            Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„: {article_data['content'][:3000]}
            
            ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {content_summary}
            
            Ù…Ø·Ù„ÙˆØ¨ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù†Ø´ÙˆØ±Ø§Øª Ù…Ù† Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ§Ù„ÙŠØ© (Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„ ÙÙ‚Ø·):
            
            1. "Ù‡Ù„ ØªØ¹Ù„Ù…ØŸ" - Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ø«ÙŠØ±Ø© Ø£Ùˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„
            2. "ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙŠÙˆÙ…" - Ø´Ø±Ø­ Ù…ØµØ·Ù„Ø­ ØªÙ‚Ù†ÙŠ Ù…Ø°ÙƒÙˆØ± ÙØ¹Ù„ÙŠØ§Ù‹ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„
            3. "Ù†ØµÙŠØ­Ø© Ø³Ø±ÙŠØ¹Ø©" - Ù†ØµÙŠØ­Ø© Ø¹Ù…Ù„ÙŠØ© Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„
            4. "Ø§Ù‚ØªØ¨Ø§Ø³ Ù…Ù„Ù‡Ù…" - Ø¬Ù…Ù„Ø© Ø£Ùˆ ÙÙƒØ±Ø© Ù…Ù„Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
            5. "Ø­Ù‚ÙŠÙ‚Ø© Ù…Ø¯Ù‡Ø´Ø©" - Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ø«ÙŠØ±Ø© Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„
            
            Ø´Ø±ÙˆØ· Ù…Ù‡Ù…Ø©:
            âœ… Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙÙ‚Ø· - Ù„Ø§ ØªØ®ØªÙ„Ù‚ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            âœ… ØªØ£ÙƒØ¯ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©
            âœ… Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
            âœ… ÙƒÙ„ Ù…Ù†Ø´ÙˆØ± 120-180 Ø­Ø±Ù (Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø±Ø§Ø¨Ø·)
            âœ… Ø§Ø³ØªØ®Ø¯Ù… 2-3 Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙ‚Ø·
            âœ… Ø£Ø¶Ù 2-3 Ù‡Ø§Ø´ØªØ§ØºØ§Øª Ø¹Ø±Ø¨ÙŠØ© Ø°Ø§Øª ØµÙ„Ø©
            âœ… Ø§Ø¬Ø¹Ù„ ÙƒÙ„ Ù…Ù†Ø´ÙˆØ± Ù…ÙÙŠØ¯ ÙˆÙ…Ø«ÙŠØ± Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù…
            âœ… Ø§Ø±Ø¨Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¨Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†
            
            ØµÙŠØºØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
            POST 1:
            [Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†Ø´ÙˆØ±]: [Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØ§Ù„Ù‡Ø§Ø´ØªØ§ØºØ§Øª]
            TYPE: [did_you_know/definition/quick_tip/inspiring_quote/amazing_fact]
            
            POST 2:
            [Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†Ø´ÙˆØ±]: [Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØ§Ù„Ù‡Ø§Ø´ØªØ§ØºØ§Øª]
            TYPE: [Ø§Ù„Ù†ÙˆØ¹]
            
            Ù…Ø«Ø§Ù„:
            POST 1:
            Ù‡Ù„ ØªØ¹Ù„Ù…ØŸ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙ…ÙƒÙ†Ù‡ ØªØ­Ù„ÙŠÙ„ 10000 ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ø§Ù„ÙˆØ§Ø­Ø¯Ø©! ğŸ¤–âš¡ Ù‡Ø°Ø§ Ù…Ø§ ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ ÙÙŠ ØªØ´Ø®ÙŠØµ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø¨Ø³Ø±Ø¹Ø© #Ø°ÙƒØ§Ø¡_Ø§ØµØ·Ù†Ø§Ø¹ÙŠ #ØªÙ‚Ù†ÙŠØ© #Ø·Ø¨
            TYPE: did_you_know
            """
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": """Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ Ø¯Ù‚ÙŠÙ‚ ÙˆØ¬Ø°Ø§Ø¨ Ù„ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ. 

Ù…Ø¨Ø§Ø¯Ø¦Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
1. Ø§Ù„Ø¯Ù‚Ø© Ø£ÙˆÙ„Ø§Ù‹ - Ù„Ø§ ØªØ®ØªÙ„Ù‚ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø¨Ø¯Ø§Ù‹
2. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ù„ ÙÙ‚Ø·
3. ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
4. Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø¬Ø°Ø§Ø¨ ÙˆÙ„ÙƒÙ† Ø§Ø­ØªØ±Ø§ÙÙŠ
5. Ø§Ø±Ø¨Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¨Ø§Ù„ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¹Ù…Ù„ÙŠ
6. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙˆØ§Ø¶Ø­Ø© ÙˆØ§Ù„Ø¨Ø³ÙŠØ·Ø©

ØªØ°ÙƒØ±: Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ ØªÙ‚Ø¯ÙŠÙ… Ù‚ÙŠÙ…Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù„Ù‚Ø§Ø±Ø¦ Ù…Ù† Ø®Ù„Ø§Ù„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙÙŠØ¯Ø©."""
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1500,
                temperature=0.5  # Lower temperature for more accurate content
            )
            
            content = response.choices[0].message.content.strip()
            
            # Parse the response to extract individual posts
            posts = []
            post_blocks = re.split(r'POST \d+:', content)[1:]  # Skip first empty element
            
            for block in post_blocks:
                lines = block.strip().split('\n')
                post_content = ""
                post_type = "general"
                
                for line in lines:
                    if line.startswith('TYPE:'):
                        post_type = line.replace('TYPE:', '').strip().lower()
                    elif line.strip() and not line.startswith('TYPE:'):
                        # Remove the post type prefix if it exists (e.g., "Ù‡Ù„ ØªØ¹Ù„Ù…ØŸ:")
                        cleaned_line = re.sub(r'^[^:]+:\s*', '', line.strip())
                        post_content += cleaned_line + " "
                
                post_content = post_content.strip()
                if post_content and len(post_content) > 20:  # Ensure we have substantial content
                    hashtags = re.findall(r'#[\w\u0600-\u06FF]+', post_content)  # Support Arabic hashtags
                    engagement_score = self._calculate_engagement_score(post_content)
                    
                    # Validate post quality
                    if self._validate_post_quality(post_content, post_type):
                        posts.append({
                            "post": post_content,
                            "hashtags": hashtags,
                            "type": post_type,
                            "engagement_score": engagement_score
                        })
            
            return posts[:num_posts]  # Ensure we return exactly the requested number
            
        except Exception as e:
            raise Exception(f"Failed to generate daily posts: {str(e)}")

    def generate_engaging_post(self, text, platform="general", max_length=280, dry_run=False):
        """
        Generate an engaging social media post from any text
        
        :param text: Original text to transform
        :param platform: Target platform (twitter, facebook, linkedin, instagram, general)
        :param max_length: Maximum length of the post
        :param dry_run: If True, still generate real posts but mark as dry run
        :return: Engaging social media post
        """
        # Generate real content even in dry run mode for testing
        
        try:
            platform_guidelines = {
                "twitter": "engaging and informative, can be longer with detailed insights, use trending hashtags",
                "facebook": "conversational, story-telling, community-focused, encourage discussion",
                "linkedin": "professional, insightful, industry-focused, thought leadership tone",
                "instagram": "visual-first, lifestyle-oriented, with many relevant hashtags, storytelling",
                "general": "versatile and adaptable to multiple platforms"
            }
            
            guideline = platform_guidelines.get(platform, platform_guidelines["general"])
            
            prompt = f"""
            Transform this text into an engaging Arabic social media post for {platform}:
            
            Original text: {text}
            
            Requirements:
            - Write in Arabic
            - Make it {guideline}
            - Keep under {max_length} characters
            - Include relevant emojis
            - Add appropriate Arabic hashtags
            - Make it click-worthy and shareable
            - Focus on emotional engagement
            
            Return just the final post, optimized for maximum engagement.
            """
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"You are a social media expert specializing in Arabic content that goes viral and drives engagement on {platform}."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.7
            )
            
            post = response.choices[0].message.content.strip()
            hashtags = re.findall(r'#\w+', post)
            
            # Simple engagement score based on content features
            engagement_score = self._calculate_engagement_score(post)
            
            return {
                "post": post,
                "hashtags": hashtags,
                "engagement_score": engagement_score,
                "platform": platform
            }
            
        except Exception as e:
            raise Exception(f"Failed to generate engaging post: {str(e)}")

    def _calculate_engagement_score(self, post):
        """
        Calculate a simple engagement score based on post features
        """
        score = 5.0  # Base score
        
        # Emoji bonus
        emoji_count = len(re.findall(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', post))
        score += min(emoji_count * 0.5, 2.0)
        
        # Hashtag bonus
        hashtag_count = len(re.findall(r'#\w+', post))
        score += min(hashtag_count * 0.3, 1.5)
        
        # Question bonus (engagement trigger)
        if 'ØŸ' in post or '?' in post:
            score += 1.0
        
        # Call to action words
        cta_words = ['Ø´Ø§Ø±Ùƒ', 'Ø¹Ù„Ù‚', 'Ø§ÙƒØªØ´Ù', 'ØªØ¹Ù„Ù…', 'Ø§Ø­ØµÙ„', 'Ø¬Ø±Ø¨']
        for word in cta_words:
            if word in post:
                score += 0.5
                break
        
        # Length penalty for very long posts
        if len(post) > 280:
            score -= 1.0
        
        return min(max(score, 1.0), 10.0)  # Keep score between 1-10

    def _analyze_article_content(self, content, title):
        """
        Analyze article content to extract key themes and information
        This helps the AI generate more accurate posts
        """
        try:
            analysis_prompt = f"""
            Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ø³ØªØ®Ø±Ø¬:
            1. Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            2. Ø£Ù‡Ù… 3 Ù†Ù‚Ø§Ø· Ø£Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
            3. Ø£ÙŠ Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ø°ÙƒÙˆØ±Ø©
            4. Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø©
            5. Ø§Ù„Ù†ØµØ§Ø¦Ø­ Ø£Ùˆ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©

            Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {title}
            Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {content[:2000]}

            Ø§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ (150 ÙƒÙ„Ù…Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰) ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© ÙÙ‚Ø·.
            """
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰ Ø¯Ù‚ÙŠÙ‚ ÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."},
                    {"role": "user", "content": analysis_prompt}
                ],
                max_tokens=300,
                temperature=0.3  # Lower temperature for more accurate analysis
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            # If analysis fails, return a basic summary
            return f"Ù…Ù‚Ø§Ù„ Ø¹Ù† {title}. ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙ‚Ù†ÙŠØ© ÙˆÙ†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ©."

    def _validate_post_quality(self, post_content, post_type):
        """
        Validate that the generated post meets quality standards
        """
        # Check minimum length
        if len(post_content) < 30:
            return False
        
        # Check for generic/template phrases that indicate poor generation
        generic_phrases = [
            "Ù‡Ø°Ø§ Ù…Ø«Ø§Ù„",
            "Ù‡Ø°Ù‡ Ù…Ø¹Ù„ÙˆÙ…Ø©",
            "ØªØ¬Ø±Ø¨Ø©",
            "dry run",
            "Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰",
            "Ù†Ù…ÙˆØ°Ø¬",
            "Ø§Ø®ØªØ¨Ø§Ø±"
        ]
        
        for phrase in generic_phrases:
            if phrase in post_content.lower():
                return False
        
        # Check that it has proper structure for the type
        if post_type == "did_you_know" and "Ù‡Ù„ ØªØ¹Ù„Ù…" not in post_content:
            return False
        elif post_type == "definition" and "ØªØ¹Ø±ÙŠÙ" not in post_content:
            return False
        elif post_type == "quick_tip" and "Ù†ØµÙŠØ­Ø©" not in post_content:
            return False
        
        # Check for Arabic content (should have some Arabic characters)
        arabic_chars = len(re.findall(r'[\u0600-\u06FF]', post_content))
        if arabic_chars < 10:  # Should have at least 10 Arabic characters
            return False
        
        return True 